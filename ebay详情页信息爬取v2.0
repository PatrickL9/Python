#!/usr/bin/python3
import requests
import re
import xlwt,xlrd
import xlutils.copy
from lxml import etree
from fake_useragent import UserAgent


ua = UserAgent()
header = {
    'User-Agent': ua.Chrome,
    'Accept-Language': 'zh-CN,zh;q=0.8,zh-TW;q=0.7,zh-HK;q=0.5,en-US;q=0.3,en;q=0.2',
    'Connection': 'keep-alive'
    }

#加载网址
def get_page(url):
    # proxies = {'http': 'http://' + get_proxy()}
    try:
        response = requests.get(url,headers = header,timeout = 10)
        if response.status_code == 200:
            # return response.content.decode('utf-8')
            return response.text
        else:
            return None
    except:
        print('初始请求失败')
        return None

#获取产品链接
def get_product_link(url,link_list):
    text = get_page(url)
    html  = etree.HTML(text)
    links = html.xpath('//div/div/ul/li[contains(@class, "s-item" )]//a[@class="s-item__link"]/@href')
    for link in links:
        link_list.append(link)

#获取产品信息
def get_product_info(link_list,save_path):
    for link in link_list:
        text = get_page(link)
        html = etree.HTML(text)
        product_id = html.xpath('//div[@id="descItemNumber"]/text()')  # ebay产品ID
        # print(''.join(product_id))
        brand = html.xpath('//div[@class="itemAttr"]//h2[@itemprop="brand"]/span/text()') #产品品牌
        # print(''.join(brand))
        product_title = html.xpath('//span[@class="u-dspn"]/text()')[0]  #产品名称
        # print(product_title)
        condition = html.xpath('//div[contains(@class,"u-flL condText")]/text()') #产品状态，是否新品或二手
        # condition_r = re.sub('\[\'|\'\]','',str(condition))
        # print(''.join(condition))
        price = html.xpath('//span[@itemprop="price"]/text()') #产品价格
        # price_r = re.sub('\[\'|\'\]','',str(price))
        # print(''.join(price))
        qty = html.xpath('//span[@id="qtySubTxt"]/span/text()') #库存数量
        # print(''.join(qty).strip())
        seller_name = html.xpath('//span[@class="mbg-nw"]/text()')[0]  #店铺名称
        # print(seller_name)
        seller_link = html.xpath('//div[@class="mbg vi-VR-margBtm3"]/a/@href')[0] #店铺链接
        # print(seller_link)
        sold = html.xpath('//span[@class="soldwithfeedback"]/span/a/text()')
        sold_r = re.findall('^\d+[,?\d+]+',''.join(sold))  #已售数量
        # print(''.join(sold_r))
        product_info = [''.join(product_id),''.join(brand),product_title,''.join(price),link,''.join(condition),''.join(qty).strip(),''.join(sold_r),seller_name,seller_link]
        save_product_info(product_info,save_path)
        # print('保存第'+str(i+1)+'个产品信息')

#保存产品信息至excel文件
def save_product_info(product_info,save_path):
    workbook = xlrd.open_workbook(save_path, formatting_info=True)
    sheet = workbook.sheet_by_index(0)
    nrows = sheet.nrows  # 获取当前excel文件所有行数
    new_workbook = xlutils.copy.copy(workbook)  # 将xlrd对象拷贝转化为xlwt对象

    # 保留excel格式
    # styleS = xlwt.XFStyle()
    # alignment = xlwt.Alignment()
    # alignment.horz = xlwt.Alignment.HORZ_CENTER
    # alignment.vert = xlwt.Alignment.VERT_CENTER
    # styleS.alignment = alignment

    new_worksheet = new_workbook.get_sheet(0)  # 获取转化后工作簿中的第一个表格
    for j in range(len(product_info)):
        new_worksheet.write(nrows,j,product_info[j])
    print('写入第'+str(nrows)+'个产品')
    new_workbook.save(save_path)


def main():
    keyword = 'toy' #查询关键字
    page = 3 #爬取页数
    link_list = []

    save_path = """E:\PythonProject\ebay_crawl\ebayProduct.xlsx"""
    # 新建文件并写入表头
    workbook = xlwt.Workbook()
    sheet1 = workbook.add_sheet('ebayProduct', cell_overwrite_ok=True)
    row_0 = ['ebay产品编码', '品牌', '产品名称', '产品价格', '产品链接', '产品状态', '库存情况', '已售数量', '店铺名称', '店铺链接']
    for i in range(len(row_0)):
        sheet1.write(0, i, row_0[i])
    workbook.save(save_path)

    for i in range(page):
        url = 'https://www.ebay.com/sch/i.html?_from=R40&_trksid=m570.l1313&_nkw=' + keyword + '&_sacat=0&_pgn=' + str(page)
        get_product_link(url, link_list)  # 爬取所有产品链接
        print('爬取第' + str(i + 1) + '页信息')
    get_product_info(link_list,save_path) #读取每个产品链接的信息并写入excel
    print('爬取结束！')


if __name__ == '__main__':
    main()
